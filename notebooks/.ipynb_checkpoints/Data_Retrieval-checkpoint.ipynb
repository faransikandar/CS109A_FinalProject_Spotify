{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Spotify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Initialize Spotify API connection. Note: we've removed our client ID / secret from this public repository;\n",
    "please use your own credentials should you wish to run this notebook.\n",
    "'''\n",
    "\n",
    "def refresh():\n",
    "    os.environ[\"SPOTIPY_CLIENT_ID\"] = 'XXX'\n",
    "    os.environ[\"SPOTIPY_CLIENT_SECRET\"] = 'XXX'\n",
    "    os.environ[\"SPOTIPY_REDIRECT_URI\"] = 'http://localhost/'\n",
    "\n",
    "    scope = 'user-library-read'\n",
    "\n",
    "    if len(sys.argv) > 1:\n",
    "        username = sys.argv[1]\n",
    "    else:\n",
    "        #print(\"Usage: %s username\" % (sys.argv[0],))\n",
    "        sys.exit()\n",
    "\n",
    "    token = util.prompt_for_user_token(username, scope)\n",
    "\n",
    "    # Print some tracks\n",
    "    if token:\n",
    "        sp = spotipy.Spotify(auth=token)\n",
    "        results = sp.current_user_saved_tracks()\n",
    "        for item in results['items']:\n",
    "            track = item['track']\n",
    "            #print(track['name'] + ' - ' + track['artists'][0]['name'])\n",
    "    else:\n",
    "        print(\"Can't get token for\", username)\n",
    "    return sp\n",
    "\n",
    "sp = refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Get all of the categories for Spotify official playlists'''\n",
    "categories = sp.categories(country=None, locale=None, limit=50, offset=0)\n",
    "\n",
    "#Get the ids of categories\n",
    "temp = categories['categories']\n",
    "\n",
    "cat_ids = []\n",
    "for item in temp['items']:\n",
    "    cat_ids.append(item['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''For each category, get playlists'''\n",
    "\n",
    "playlists = {}\n",
    "for cat_id in cat_ids:\n",
    "    playlists[cat_id] = sp.category_playlists(category_id=cat_id, country=None, limit=50, offset=0)\n",
    "\n",
    "playlist_ids_by_cat = {}\n",
    "for category, playlist in playlists.items():\n",
    "    #print(playlist['playlists']['items'][0]['id'])\n",
    "    playlist_ids_by_cat[category] = [x['id'] for x in playlist['playlists']['items']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Useful track-getting functions!\n",
    "'''\n",
    "\n",
    "def spotify_id_to_isrc(spotify_ids):\n",
    "    '''\n",
    "    converts spotify ids to isrcs\n",
    "    '''\n",
    "    tracks = sp.tracks(spotify_ids)\n",
    "    return [x['external_ids']['isrc']  for x in tracks['tracks']]\n",
    "\n",
    "def isrc_to_spotify_id(isrcs):\n",
    "    '''\n",
    "    converts isrcs to spotify ids\n",
    "    This takes a while since we need to search\n",
    "    Note: isrc --> spotify_id is not necessarily a one-to-one mapping (multiple spotify ids\n",
    "    can map to the same isrc)\n",
    "    ''' \n",
    "    ids = []\n",
    "    for isrc in isrcs:\n",
    "        ids.append(sp.search('isrc:'+isrc)['tracks']['items'][0]['id'])\n",
    "    return ids\n",
    "\n",
    "def get_popularity_and_markets(spotify_ids):\n",
    "    '''\n",
    "    Given a list of spotify IDs, get the popularity and market info for the songs\n",
    "    '''\n",
    "    chunk_size= 42\n",
    "    tmp = {}\n",
    "    for i in range(0, len(spotify_ids), chunk_size):\n",
    "        chunk = spotify_ids[i:i+chunk_size]\n",
    "        features = sp.tracks(chunk)['tracks']\n",
    "        features  = pd.DataFrame([x for x in features if isinstance(x, dict)])\n",
    "        tmp_df = pd.DataFrame(features)\n",
    "        tmp_df.index = tmp_df['id']\n",
    "        tmp_df = tmp_df[['id', 'popularity', 'available_markets']]\n",
    "        tmp_df['available_markets'] = tmp_df['available_markets'].apply(len)\n",
    "        tmp.update(tmp_df.T.to_dict())\n",
    "    df = pd.DataFrame(tmp).T\n",
    "    return df\n",
    "\n",
    "def get_followers(playlist_id, user = 'spotify'):\n",
    "    '''\n",
    "    Get the # of follower of a playlist\n",
    "    '''\n",
    "    playlist = sp.user_playlist(user, playlist_id=playlist_id, fields = ['followers'])\n",
    "    return playlist['followers']['total']\n",
    "\n",
    "#Default: US, 11/24/2017 at 8PM\n",
    "def get_featured_playlists(country = 'US', time = '2017-11-24T18:00:00'):\n",
    "    '''\n",
    "    Get whether or not a playlist was featured on a certain date at a certain time.\n",
    "    '''\n",
    "    featured = sp.featured_playlists(country=country, timestamp=time, limit=50, offset=0)\n",
    "    return [x['id'] for x in featured['playlists']['items']]\n",
    "\n",
    "def get_track_ids(playlist_id = '37i9dQZF1DX3FNkD0kDpDV'):\n",
    "    ''' \n",
    "    Given a Spotify Playlist ID, returns a list of spotify ids for songs in playlist\n",
    "    '''\n",
    "    offset = 0\n",
    "    playlist = sp.user_playlist_tracks(user = 'spotify', playlist_id = playlist_id, limit = 100)\n",
    "    ids = [x['track']['id']  for x in playlist['items']]\n",
    "    # if we hit the limit, need to add more\n",
    "    while len(ids) / (offset + 100) == 1:\n",
    "        offset = offset + 100\n",
    "        playlist = sp.user_playlist_tracks(user = 'spotify', playlist_id = playlist_id, limit = 100, offset = offset)\n",
    "        ids = ids + [x['track']['id']  for x in playlist['items']]\n",
    "    return ids\n",
    "\n",
    "def get_track_audio_features(spotify_ids = get_track_ids()):\n",
    "    'Given a list of spotify IDs, returns a dataframe of track audio features'\n",
    "    chunk_size= 42\n",
    "    tmp = {}\n",
    "    for i in range(0, len(spotify_ids), chunk_size):\n",
    "        chunk = spotify_ids[i:i+chunk_size]\n",
    "        features = sp.audio_features(chunk)\n",
    "        if features:\n",
    "            tmp_df = pd.DataFrame([x for x in features if isinstance(x, dict)])\n",
    "            tmp_df.index = tmp_df['id']\n",
    "            tmp.update(tmp_df.T.to_dict())\n",
    "    df = pd.DataFrame(tmp).T\n",
    "    df = df.drop(['analysis_url', 'track_href', 'uri', 'type'], 1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_playlist_data(playlist_ids):\n",
    "    '''\n",
    "    Given a list of Spotify playlist IDs, returns a dataframe containing a row\n",
    "    for each inputed playlist with columns for the following data:\n",
    "    1) *average* audio characteristics for the songs in that playlist:\n",
    "        acousticness, danceability, duration,\n",
    "        energy, instrumentalness, key, liveness, loudness, mode, tempo,\n",
    "        valence, and time signature\n",
    "    2) average popularity of songs in the playlist\n",
    "    3) popularity of most popular song in playlist (might be an anchor song to the playlist)\n",
    "    4) average # of markets the songs in the playlist are available i\n",
    "    5) global playlist info\n",
    "        - number of followers the playlist has (response variable?)\n",
    "        - number of tracks in playlist\n",
    "        - whether or not the playlist was \"featured\" on 11/24/2017 at 8PM\n",
    "    '''\n",
    "    rez = {}\n",
    "    # force list\n",
    "    if not isinstance(playlist_ids, list):\n",
    "        playlist_ids = [playlist_ids]\n",
    "        \n",
    "    featured_playlists = get_featured_playlists()\n",
    "    audio_char_dict = {}\n",
    "    popularity_dict = {}\n",
    "    for playlist_id in playlist_ids:\n",
    "        print('Getting info for: ' + playlist_id)\n",
    "        tmp = {}\n",
    "        try:\n",
    "            track_ids = get_track_ids(playlist_id)\n",
    "        except spotipy.client.SpotifyException:\n",
    "            print('WARNING: Playlist does not exist. Skipping.')\n",
    "            continue\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "            track_ids = get_track_ids(playlist_id)\n",
    "        # get average audio characteristics\n",
    "        audio_chars = get_track_audio_features(track_ids)\n",
    "        audio_char_mean = audio_chars.mean().to_dict()\n",
    "        # get popularity and markets\n",
    "        pop_and_mkts = get_popularity_and_markets(track_ids)\n",
    "        pop_and_mkts_mean = pop_and_mkts.mean().to_dict()\n",
    "        audio_char_dict.update(audio_chars.T.to_dict())\n",
    "        popularity_dict.update(pop_and_mkts.T.to_dict())\n",
    "        # get # followers\n",
    "        tmp['num_followers'] = get_followers(playlist_id)\n",
    "        tmp['num_tracks'] = len(track_ids)\n",
    "        tmp['featured'] = 1 if playlist_id in featured_playlists else 0\n",
    "        tmp.update(audio_char_mean)\n",
    "        tmp.update(pop_and_mkts_mean)\n",
    "        rez[playlist_id] = tmp\n",
    "    return pd.DataFrame(rez).T, popularity_dict, audio_char_dict\n",
    "\n",
    "\n",
    "# Loop through all of our playlists and get popularity info, track feature info, and \n",
    "progress = 0\n",
    "playlist_level_data = {}\n",
    "for cat, playlists in playlist_ids_by_cat.items():\n",
    "    if playlists[0] in playlist_level_data.keys():\n",
    "        continue\n",
    "    sp = refresh()\n",
    "    #print('Starting Category: ' + cat)\n",
    "    playlist_data, pop, audio = get_playlist_data(playlists)\n",
    "    playlist_data['category'] = cat\n",
    "    song_level_data_pop.update(pop)\n",
    "    song_level_data_audio.update(audio)\n",
    "    playlist_level_data.update(playlist_data.T.to_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Store all of this data. Uncomment + re-run ONLY IF YOU WANT TO OVERWRITE ALL OF THE CURRENT DATA\n",
    "\n",
    "# pickle.dump(pd.DataFrame(playlist_level_data).T, open( \"playlist_level_data_20171203.p\", \"wb\" ) )\n",
    "# pickle.dump(pd.DataFrame(song_level_data_pop).T, open( \"song_level_data_pop_20171203.p\", \"wb\" ) )\n",
    "# pickle.dump(pd.DataFrame(song_level_data_audio).T, open( \"song_level_data_audio_20171203.p\", \"wb\" ) )\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loop through all of our playlists and store the track IDs from each playlists;\n",
    "we use this to get a mapping of playlists to tracks (could theoreticallly have done this above,\n",
    "but we tragically did not.)\n",
    "'''\n",
    "playlist_to_tracks = {}\n",
    "progress = 1\n",
    "for cat, playlists in playlist_ids_by_cat.items():\n",
    "    print(progress / len(playlist_ids_by_cat))\n",
    "    for playlist in playlists:\n",
    "        try:\n",
    "            track_ids = get_track_ids(playlist)\n",
    "        except spotipy.client.SpotifyException:\n",
    "            print('WARNING: Playlist does not exist. Skipping.')\n",
    "            continue\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "            track_ids = get_track_ids(playlist)\n",
    "        playlist_to_tracks[playlist] = track_ids\n",
    "    progress += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Store playlist to track info\n",
    "\n",
    "# Uncomment and run if you want to store again\n",
    "\n",
    "#pickle.dump(playlist_to_tracks, open( \"playlist_to_track_20171203.p\", \"wb\" ) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Million Songs Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Merge in Million Songs Database\n",
    "'''\n",
    "\n",
    "'''\n",
    "Get links from Echonest to match MSD to Spotify data\n",
    "'''\n",
    "\n",
    "spotify_ids_in_playlists = set(song_level_data_pop.index).union(set(song_level_data_audio.index))\n",
    "loc = 'millionsongdataset_echonest.tar/millionsongdataset_echonest/millionsongdataset_echonest/'\n",
    "\n",
    "def msd_to_spotify(msd_id):\n",
    "    folder = msd_id[2:4]\n",
    "    with open(loc + folder + '/' + msd_id+'.json') as f:\n",
    "        file = json.load(f)\n",
    "        try:\n",
    "            tmp = file['response']['songs'][0]['tracks']\n",
    "            spotify_ids = [x['foreign_id'] for x in tmp if 'spotify' in x['catalog']]\n",
    "            ids = [y.split('spotify:track:')[1] for y in spotify_ids]\n",
    "            ids = [x for x in ids if x in spotify_ids_in_playlists]\n",
    "        except:\n",
    "            return np.NaN\n",
    "    if ids:\n",
    "        return ids[0]\n",
    "    else:\n",
    "        return np.NaN\n",
    "    \n",
    "msd_id = pd.Series(msd_data.index, index = msd_data.index)\n",
    "msd_to_spotify_map = msd_id.apply(msd_to_spotify)\n",
    "\n",
    "with open('msd_map_20171203.p', 'wb') as f:\n",
    "    pickle.dump(msd_to_spotify_map, f)\n",
    "    \n",
    "with open('msd_map_20171203.p', 'rb') as f:\n",
    "    msd_map = pickle.load(f).dropna()\n",
    "    msd_map = pd.Series(msd_map.to_dict())\n",
    "\n",
    "msd_summary = h5py.File('msd_summary_file.h5', 'r')\n",
    "idx = msd_summary['metadata']['songs']['song_id']\n",
    "idx = [x.decode('ascii') for x in idx]\n",
    "song_hotness = msd_summary['metadata']['songs']['song_hotttnesss']\n",
    "artist_hotness = msd_summary['metadata']['songs']['artist_hotttnesss']\n",
    "artist_familiarity = msd_summary['metadata']['songs']['artist_familiarity']\n",
    "\n",
    "msd_data = pd.DataFrame([(x,y,z) for x,y,z in zip(song_hotness, artist_hotness, artist_familiarity)], index = idx)\n",
    "msd_data = msd_data.loc[msd_map.index]\n",
    "msd_data = pd.DataFrame(msd_data.values, index = [msd_map[x] for x in msd_data.index])\n",
    "msd_data.columns = ['song_hot', 'artist_hot', 'artist_famil']\n",
    "\n",
    "with open('msd_data_20171203.p', 'wb') as f:\n",
    "    pickle.dump(msd_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Merge all of our data together\n",
    "'''\n",
    "\n",
    "rez = {}\n",
    "for playlist, tracks in playlist_to_track.items():\n",
    "    audio_data = song_level_data_audio.reindex(tracks)\n",
    "    popularity_data = song_level_data_pop.reindex(tracks)\n",
    "    operations = {'max':np.max, 'mean':np.mean, 'median':np.median, 'min':np.min, 'sd':np.std}\n",
    "    combined = audio_data.join(popularity_data, rsuffix ='_pop').join(msd_data)\n",
    "    columns = [x for x in combined.columns if x not in ['id', 'id_pop']]\n",
    "    rez[playlist] = {}\n",
    "    for operation_name, operation in operations.items():\n",
    "        new = combined[columns].apply(operation)\n",
    "        new.index = [x+'_'+operation_name for x in columns]\n",
    "        new.name = operation_name\n",
    "        rez[playlist].update(new)\n",
    "    for feature in ['key', 'mode', 'time_signature']:\n",
    "        rez[playlist][feature+'_'+'mode'] = combined[feature].mode().values[0]\n",
    "\n",
    "def aggregate_to_playlist_level(tracks):\n",
    "    rez = {}\n",
    "    audio_data = song_level_data_audio.reindex(tracks)\n",
    "    popularity_data = song_level_data_pop.reindex(tracks)\n",
    "    operations = {'max':np.max, 'mean':np.mean, 'median':np.median, 'min':np.min, 'sd':np.std}\n",
    "    combined = audio_data.join(popularity_data, rsuffix ='_pop').join(msd_data)\n",
    "    columns = [x for x in combined.columns if x not in ['id', 'id_pop']]\n",
    "    for operation_name, operation in operations.items():\n",
    "        new = combined[columns].apply(operation)\n",
    "        new.index = [x+'_'+operation_name for x in columns]\n",
    "        new.name = operation_name\n",
    "        rez.update(new.to_dict())\n",
    "    for feature in ['key', 'mode', 'time_signature']:\n",
    "        rez[feature+'_'+'mode'] = combined[feature].mode().values[0]\n",
    "    rez['category'] = track_categories.reindex(tracks).mode()[0]\n",
    "    rez['num_tracks'] = len(tracks)\n",
    "    rez['featured'] = 0\n",
    "    return rez\n",
    "\n",
    "aggregate_data = pd.DataFrame(rez).T\n",
    "aggregate_data = aggregate_data.join(playlist_level_data[['category', 'featured', 'num_followers', 'num_tracks']])\n",
    "aggregate_data = aggregate_data.dropna(subset = ['category'])\n",
    "\n",
    "vars_to_keep = ['acousticness_max', 'acousticness_mean', 'acousticness_median', 'acousticness_min', 'acousticness_sd', \n",
    "'category', 'danceability_max', 'danceability_mean', 'danceability_median', 'danceability_min', \n",
    "'danceability_sd', 'duration_ms_max', 'duration_ms_mean', 'duration_ms_median', 'duration_ms_min', \n",
    "'duration_ms_sd', 'energy_max', 'energy_mean', 'energy_median', 'energy_min', 'energy_sd', 'featured',\n",
    "'instrumentalness_max', 'instrumentalness_mean', 'instrumentalness_median', 'instrumentalness_min', \n",
    "'instrumentalness_sd', 'key_mode', 'liveness_max', 'liveness_mean', 'liveness_median', 'liveness_min', \n",
    "'liveness_sd', 'loudness_max', 'loudness_mean', 'loudness_median', 'loudness_min', 'loudness_sd', \n",
    "'mode_mean', 'mode_median', 'mode_mode', 'available_markets_max', 'available_markets_mean', \n",
    "           'available_markets_median', 'available_markets_min', 'available_markets_sd', 'popularity_max', \n",
    "'popularity_mean', 'popularity_median', 'popularity_min', 'popularity_sd', 'speechiness_max', \n",
    "'speechiness_mean', 'speechiness_median', 'speechiness_min', 'speechiness_sd', 'tempo_max', 'tempo_mean', \n",
    "'tempo_median', 'tempo_min', 'tempo_sd', 'time_signature_mode', 'valence_max', 'valence_mean', \n",
    "'valence_median', 'valence_min', 'valence_sd', 'artist_famil_max', 'artist_famil_mean', \n",
    "'artist_famil_median', 'artist_famil_min', 'artist_famil_sd', 'artist_hot_max', \n",
    "'artist_hot_mean', 'artist_hot_median', 'artist_hot_min', 'artist_hot_sd', \n",
    "'song_hot_max', 'song_hot_mean', 'song_hot_median', 'song_hot_min', \n",
    "'song_hot_sd', 'num_followers'\n",
    "          , 'num_tracks'\n",
    "          ]\n",
    "\n",
    "with open('aggregate_data.p', 'wb') as f:\n",
    "    data = pickle.dump(aggregate_data[vars_to_keep], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Determine track-level category based on playlists that contain it -- this is a rather crude measure, but works well\n",
    "'''\n",
    "\n",
    "track_category = {}\n",
    "for playlist, tracks in playlist_to_track.items():\n",
    "    try:\n",
    "        playlist_category = playlist_level_data['category'][playlist]\n",
    "    except:\n",
    "        pass\n",
    "    for track in tracks:\n",
    "        if track_category.get(track, None):\n",
    "            if track_category[track].get(playlist_category, None):\n",
    "                track_category[track][playlist_category] += 1\n",
    "            else:\n",
    "                track_category[track][playlist_category] = 1\n",
    "        else:\n",
    "            track_category[track] = {playlist_category : 1}\n",
    "rez = {}\n",
    "for track, d in track_category.items():\n",
    "    rez[track] = pd.Series(d).idxmax()\n",
    "    \n",
    "#Store this\n",
    "with open('track_categories_20171203.p', 'wb') as f:\n",
    "    pickle.dump(rez, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Generate fake playlists to use later (we will choose among these fake playlists to pick one that theoretically\n",
    "would have the most followers\n",
    "'''\n",
    "\n",
    "with open('track_categories_20171203.p', 'rb') as f:\n",
    "    track_categories = pd.Series(pickle.load(f))\n",
    "\n",
    "num_per_category = 100\n",
    "candidate_playlists = {}\n",
    "playlist_id_to_songs = {}\n",
    "possible_songs = list(spotify_ids_in_playlists)\n",
    "possible_categories = list(set(track_categories.values))\n",
    "i = 0\n",
    "for category in possible_categories:\n",
    "    songs_in_cat = track_categories.where(track_categories == category).dropna().index\n",
    "    for j in range(0, num_per_category):\n",
    "        tracks = np.random.choice(songs_in_cat, 30, replace = False)\n",
    "        candidate_playlists[i] = aggregate_to_playlist_level(tracks)\n",
    "        playlist_id_to_songs[i] = tracks\n",
    "        i += 1\n",
    "candidate_playlists = pd.DataFrame(candidate_playlists).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Store fake playlists'''\n",
    "\n",
    "with open('candidate_playlists_to_songs_20171205.p', 'wb') as f:\n",
    "    pickle.dump(playlist_id_to_songs, f)\n",
    "with open('candidate_playlists_20171205.p', 'wb') as f:\n",
    "    pickle.dump(candidate_playlists[[x for x in vars_to_keep if x != 'num_followers']], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
